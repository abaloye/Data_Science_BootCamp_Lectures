{"cells":[{"cell_type":"markdown","metadata":{"id":"0uDnpLegEcFh"},"source":["# Importing Data"]},{"cell_type":"markdown","metadata":{"id":"lW8J6b6KEcFv"},"source":["## Reading CSV and TXT files\n","\n","Rather than creating Series or Dataframe stucture from scrach, or even from Python core sequence or\n","ndarrays, the most typical use of Pandas is based on the loading of information from files or sources of information\n","for further exploration, transformation and analysis\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5KDFX1iEcFw"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"V3p2uzqeEcFz"},"source":["Reading data with Python\n","\n","As we saw on previous courses we can read data simply using Python\n","\n","When you want to work with a file, the first thing to do is to open it. This is done by invoking the open( ) built-in function.\n","\n","open() has a single required argument that is the path to the file and has a single return, the file object.\n","\n","The with statement automatically takes care of closing the file onces  it leaves the with block, even in cases of error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Im1aOXQLEcF0"},"outputs":[],"source":["with open('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv', 'r') as fp:\n","    print(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drnFBoQ9EcF0"},"outputs":[],"source":["Once the file is opened,we can read its content as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-BhUs8sEcF1"},"outputs":[],"source":["with open('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv', 'r') as fp:\n","    for index, line in enumerate(fp.readlines()):\n","        # read just the first 10 lines\n","        if (index<10):\n","            print(index, line)\n"]},{"cell_type":"markdown","metadata":{"id":"JqSA1RhlEcF2"},"source":["How can we process the data read from the file using pure Python? it involves a lot of manual work, for example, splitting the values by the correct seperator:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWRBdQDLEcF4","outputId":"cb52955b-a86d-4005-b75f-3cfbffbe0f03"},"outputs":[{"name":"stdout","output_type":"stream","text":["2017-04-02 00:00:00: $1099.169125\n","\n","2017-04-03 00:00:00: $1141.813\n","\n","2017-04-04 00:00:00: $1141.6003625\n","\n","2017-04-05 00:00:00: $1133.0793142857142\n","\n","2017-04-06 00:00:00: $1196.3079375\n","\n","2017-04-07 00:00:00: $1190.45425\n","\n","2017-04-08 00:00:00: $1181.1498375\n","\n","2017-04-09 00:00:00: $1208.8005\n","\n","2017-04-10 00:00:00: $1207.744875\n","\n","2017-04-11 00:00:00: $1226.6170375\n","\n"]}],"source":["with open('btc-market-price(1).csv', 'r') as fp:\n","    for index, line in enumerate(fp.readlines()):\n","        # read just the first 10 lines\n","        if (index<10):\n","            timestamp, price = line.split(',')\n","            print(f'{timestamp}: ${price}')"]},{"cell_type":"markdown","metadata":{"id":"2MTox0QTEcF7"},"source":["But what happens if the seperator is unknown, like in the file exam_review.csv:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZi3sYnYEcF8","outputId":"796157ea-b640-49b1-d181-8e26eb447224"},"outputs":[{"name":"stdout","output_type":"stream","text":["first_name>last_name>age>math_score>french_score\n","Ray>Morley>18>\"68,000\">\"75,000\"\n","Melvin>Scott>24>77>83\n","Amirah>Haley>22>92>67\n","\n","Gerard>Mills>19>\"78,000\">72\n","Amy>Grimes>23>91>81\n"]}],"source":["!head exam_review.csv"]},{"cell_type":"markdown","metadata":{"id":"NgrHvkBZEcF8"},"source":["Note: using an exclamation mark before the command will pass the command to the shell (not to the Python interpreter). \n","\n","A shell is a computer program that presents a command line interface which allows you to control your computer using commands entered with a keyboard instead of controlling graphical user interfaces (GUIs) with a mouse/keyboard/touchscreen combination"]},{"cell_type":"markdown","metadata":{"id":"dyoWzkxQEcF9"},"source":["In this case, the seperator is not a comma, but the > sign. It's still a 'CSV', although not technically seperated by commas."]},{"cell_type":"markdown","metadata":{"id":"-aMQBEriEcF9"},"source":["The CSV module\n","Python includes the builtin module csv that helps a little bit more with the process of reading CSVs:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8t94djLIEcF-"},"outputs":[],"source":["import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWNKDVR0EcF-"},"outputs":[],"source":["with open('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv', 'r') as fp:\n","    reader = csv.reader(fp)\n","    for index, (timestamp, price) in enumerate(reader):\n","        # read just the first 10 lines\n","        if (index<10):\n","            print(f'{timestamp}: ${price}')"]},{"cell_type":"markdown","metadata":{"id":"mW6CZ8vkEcF_"},"source":["The csv modules takes care of splitting the file using a given seperator(called delimiter) and creating an"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riu4iAacEcF_"},"outputs":[],"source":["with open('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\exam_review.csv', 'r') as fp:\n","    reader = csv.reader(fp, delimiter='>')# special delimiter\n","    next(reader) # skipping header\n","    for index, values in enumerate(reader):\n","        if not values:\n","            continue # skip empty lines\n","        fname, lname,age, math, french = values\n","            print(f'{fname}{lname}(age{age} got{math} in Math and {french} in French' )"]},{"cell_type":"markdown","metadata":{"id":"ccT90eQDEcGA"},"source":["## Reading our first CSV file"]},{"cell_type":"markdown","metadata":{"id":"tgFtxY3lEcGA"},"source":["Everytime we call read_csv method, we'll need to    filepath parameter indicating the path where our csv file is:\n","\n","Any valid string is acceptable. The string could be a URL Schemes include HTTP, FTP, S3, and file. For file URLs, a host is expected. A local file could be:\n","    file://localhost/path/to/table.csv.\n","        \n","For example we can use read_csvmmethod to load data directly from an URL:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQyEJuBGEcGB","executionInfo":{"status":"error","timestamp":1653228870940,"user_tz":-60,"elapsed":38,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"f16d4fe4-39b0-4f84-8ea6-06ff47fdb1b9","colab":{"base_uri":"https://localhost:8080/","height":183}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-03b5171672dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["csv_url = ''\n","pd.read_csv(csv_url).head()"]},{"cell_type":"markdown","metadata":{"id":"W20B7TI1EcGB"},"source":["Or just use a local file:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ny37wO47EcGB"},"outputs":[],"source":["df = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv')\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"dXpvyN1DEcGC"},"source":["In this case we let pandas infer everything related to our data, but in most of the cases we'll need to explicitly tell pandas how we want our data to be loaded. To do that we use parameters.\n","\n","Lets see how theses parameters work."]},{"cell_type":"markdown","metadata":{"id":"0QkLUFb-EcGC"},"source":["First row behaviour with header parameter"]},{"cell_type":"markdown","metadata":{"id":"T7YNnMimEcGC"},"source":["The CSV file we're reading has only two columns: Timestamp and price. It doesn't have a header. Pandas automatically assigned the first row of data as headers, which is incorrect. we can\n","overwrite this behaviour with the header parameter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhh_1F5JEcGC"},"outputs":[],"source":["df= pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv', header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POGmbowPEcGD"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"_LshL-y6EcGD"},"source":["## Missing Values with na_values parameter"]},{"cell_type":"markdown","metadata":{"id":"07T4IAkcEcGD"},"source":["We can define a na_values parameter with the values we want to be recognized as NA/NAN. In this case empty string '', ? and - will be recognized as null values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zz7vi4tEEcGE"},"outputs":[],"source":["df = pd.read_csv('btc-market-price(1).csv', \n","                  header=None,\n","                  na_values=['', '?', '-'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hcT4kpKJEcGE","outputId":"0495618d-6995-4315-b002-97eb644d72c2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-04-02 00:00:00</td>\n","      <td>1099.169125</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-03 00:00:00</td>\n","      <td>1141.813000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-04 00:00:00</td>\n","      <td>1141.600363</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-04-05 00:00:00</td>\n","      <td>1133.079314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-04-06 00:00:00</td>\n","      <td>1196.307937</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     0            1\n","0  2017-04-02 00:00:00  1099.169125\n","1  2017-04-03 00:00:00  1141.813000\n","2  2017-04-04 00:00:00  1141.600363\n","3  2017-04-05 00:00:00  1133.079314\n","4  2017-04-06 00:00:00  1196.307937"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"XeOa2_1-EcGE"},"source":["## Column names using names parameter"]},{"cell_type":"markdown","metadata":{"id":"oEqwywmeEcGG"},"source":["we'll add that column names using the names parameter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yg8o51ybEcGH"},"outputs":[],"source":["df = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv',\n","                  header=None,\n","                  na_values=['', '?','-'],\n","                  names=['Timestamp','Price'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYce5QtzEcGL"},"outputs":[],"source":["df.head()df.info()"]},{"cell_type":"markdown","metadata":{"id":"VVCXFbQQEcGM"},"source":["## Column type using dtype paarameter"]},{"cell_type":"markdown","metadata":{"id":"_OYZl72nEcGN"},"source":["Without using the dtype parameter pandas will try to figure it out this type of each column automatically. We can use dtype parameter to force pandas to use certain dtype.\n","\n","in this case we'll force the price column to be float"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqY2SKnNEcGN"},"outputs":[],"source":["df = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv',\n","                  header=None,\n","                  na_values=['', '?','-'],\n","                  names=['Timestamp','Price'],\n","                  dtype={'Price': 'float'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHVpjgwYEcGN"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBVbl5JqEcGO"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"2gadCRfQEcGO"},"source":["The Timestamp column was interpreted as a regular string (object in pandas notation), we can parse it manually using a vectorized operation as we saw on previous courses.\n","\n","We'll parse Timestamp column to Datetime objects using to_datetime method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hc19lAmOEcGO"},"outputs":[],"source":["pd.to_datetime(df['Timestamp']).head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HO9llDghEcGO"},"outputs":[],"source":["df['Timestamp']= pd.to_datetime(df['Timestamp'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sV2isHXyEcGP"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xn6KTIEfEcGP"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"IV_T_fR-EcGP"},"source":["## Date parser using parse_dates patameter"]},{"cell_type":"markdown","metadata":{"id":"IrIPRJbbEcGR"},"source":["Another way of dealing with Datetime objects is using parse_dates parameter with the position of the columns with dates."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDaNeyZfEcGR"},"outputs":[],"source":["df = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv',\n","                  header=None,\n","                  na_values=['', '?','-'],\n","                  names=['Timestamp','Price'],\n","                  dtype={'Price': 'float'},\n","                  parse_dates=[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3zWFG_kEcGS"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulXi8LS8EcGS"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"91vs2ID_EcGS"},"source":["### Adding index to our data using index_col parameter"]},{"cell_type":"markdown","metadata":{"id":"eU2I81ofEcGS"},"source":["By default, pandas willl automatically assign a numeric autoincrement index or row label starting with zero. You may want to leave the default index as such if your data doesn't have a column with\n","unique values that can serve as a better index. In case ... column that you feel would serve as a better index, you can override the default behaviour by setting index_col property to a column.\n","It takes a numeric value representing the index or a string of the column name for setting a single column as index or a list of numeric values or strings for creating a multi-index.\n","\n","In our data, we are choosing the first column, Timestamp, as index(index=0) by passing zero to the index_col argument. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XTE8zVaEcGS"},"outputs":[],"source":["df = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\btc-market-price(1).csv',\n","                  header=None,\n","                  na_values=['', '?','-'],\n","                  names=['Timestamp','Price'],\n","                  dtype={'Price': 'float'},\n","                  parse_dates=[0],\n","                  index_col=[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DUcRe-6pEcGS"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKuext7sEcGT"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"DOIyyfMeEcGT"},"source":["## A more challenging parsing\n","\n","Now we'll read another CSV file. This file has the following columns:\n","`\n","- first_name\n","- last_name\n","- age\n","- math_score\n","- french_score\n","- next_test_date\n","\n","Let's read it and see how it looks like."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"yxRcuJtSEcGT"},"outputs":[],"source":["import pandas as pd\n","exam_df = df = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Desktop\\\\anaconda\\\\DATA_SCIENCE_SOI_VIDEOS\\\\wk2\\\\exam_review.csv')\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-kUvoycEcGU"},"outputs":[],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"lkVt_w-5EcGU"},"source":["### Custom` data delimiters using sep parameter"]},{"cell_type":"markdown","metadata":{"id":"RDlLInaPEcGU"},"source":["we can define which delimiters using sep parameter. If we don't use the sep parameter, pandas will automatically detect the separator.\n","\n","In most of the CSV files seperator will be comma( , )and will be automatically detected. But we can find files with other seperators like semicolon(;), tabs(\\t, specially on TSV files), whitespaces\n","or any other special character.\n","\n","In this case the seperator is a> character."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uohzale6EcGU"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv',\n","                     sep='>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaFlaqhFEcGU"},"outputs":[],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"5VNbDt_4EcGU"},"source":["### Custom data encoding"]},{"cell_type":"markdown","metadata":{"id":"8o9FgqSXEcGV"},"source":["Files are stored using different'encodings'. You've probably heard about ASCII, UTF-8, latin1, etc.\n","\n","While reading data custom encoding can be defined with the encoding parameter.\n","- encoding='UTF-8': will be used if data is UTF-8 encoded.\n","- encoding='iso-8859-1': will be used if data is ISO/IEC 8859-1('extended ASCII') encoded.\n","\n","In our case we don't need a custom encoding as data is properly loaded.\n"]},{"cell_type":"markdown","metadata":{"id":"MAk2ovP2EcGV"},"source":["### Custom numeric decimal and thousands character"]},{"cell_type":"markdown","metadata":{"id":"o9ybTnnKEcGV"},"source":["The decimal and thousands characters could change between datasets. If we have a column containing a comma(,)to indicate the decimal or thousands place, then this column would be\n","considered a string and not numeric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzhHJtNXEcGV"},"outputs":[],"source":["exam_df = pd.read_csv('exam_review.csv\n","                      sep='>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBHBfjR0EcGW"},"outputs":[],"source":["exam_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEH8NnZfEcGW"},"outputs":[],"source":["exam_df[['math_score','french_score']].dtypes"]},{"cell_type":"markdown","metadata":{"id":"T62Rq-bvEcGW"},"source":["To solve that,ensuring such columns are interpreted as integer values,we'll need to use the decimal and/or thousands parameters to indicate correction decimal and/or thousand indicators"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wv6R5iaEcGW"},"outputs":[],"source":["exam_df=pd.read_csv('exam_review.csv,'\n","                    sep='>,\n","                    decimal=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hs4_HjVjEcGW"},"outputs":[],"source":["exam_df"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"zpPGexRaEcGW","outputId":"4a336d02-ad9e-470c-a7a4-498f0b056d1d"},"outputs":[{"ename":"SyntaxError","evalue":"unexpected EOF while parsing (<ipython-input-2-c3a52393e90e>, line 1)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-c3a52393e90e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    exam_df[['maths'\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":["exam_df[['math_score', 'french_score']].dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1m50pMfEcGX"},"outputs":[],"source":["let's see what happens with the thousands parameter:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9C-ZUCPUEcGX"},"outputs":[],"source":["pd.read_csv('exam_reveiw.csv',\n","            sep='>'\n","            thousand=',')\n","        "]},{"cell_type":"markdown","metadata":{"id":"eDY9HUPaEcGX"},"source":["## Excluding specific rows"]},{"cell_type":"markdown","metadata":{"id":"fSo7gVRGEcGX"},"source":["We can use the skiprows to:\n","    - Exclude reading specified number of rows from the beginning of a file,by passing an integer argument. This removes the header too.\n","    - Skip reading specific row indices from a file, by passing a list containing row indices to skip."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkxXuafIEcGX"},"outputs":[],"source":["exam_df = pd.read_csv('exam_reveiw.csv',\n","            sep='>'\n","            decimal=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7nK66C5EcGY"},"outputs":[],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"ZEuAoST-EcGb"},"source":["To skip reading the first 2 rows from this file, we can use skiprows=2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0PmHjPYEcGc"},"outputs":[],"source":["pd.read_csv('exam_reveiw.csv',\n","            sep='>'\n","            skiprows=',')"]},{"cell_type":"markdown","metadata":{"id":"Wdngl6-FEcGc"},"source":["As the header is considered as the first row, to skip reading data rows 1 and 3, we can use skiprows =[1,3]:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmMatoy5EcGc"},"outputs":[],"source":["exam_df = pd.read_csv('exam_reveiw.csv',\n","            sep='>'\n","            decimal=',',\n","            skiprows=[1,3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7reTjc1eEcGd"},"outputs":[],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"GRhAmlw6EcGd"},"source":["### Get rid of blank lines"]},{"cell_type":"markdown","metadata":{"id":"1yjfJfsbEcGe"},"source":["The skip_blank_lines parameter is set to True so blank lines are skipped while we read files.\n","\n","If we set this parameter to False, then every blank line will be loaded with NaN values into the DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gyELz9V5EcGe"},"outputs":[],"source":["pd.read_csv('exam_reveiw.csv',\n","            sep='>'\n","            skip_blank_lines=False)"]},{"cell_type":"markdown","metadata":{"id":"ydXm-eHDEcGe"},"source":["### Loading specific columns"]},{"cell_type":"markdown","metadata":{"id":"JgrED88kEcGe"},"source":["we can use the usecols parameter when we want to load just specific columns and not all of them.\n","\n","Performance wise, it is better because instead of loading an entire datadrame into memory and then deleting the not required columns, we can select the columns that we'll need, while loading the\n","dataset itself.\n","\n","As a parameter to usecols, you can pass either a list of strings corresponding to the column names or a list of integers corresponding to column index."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBxBmcinEcGe"},"outputs":[],"source":["pd.read_csv('exam_reveiw.csv',\n","            usecols=[0,1,2],\n","            sep='>')\n","            "]},{"cell_type":"markdown","metadata":{"id":"5qFeTshFEcGf"},"source":["### Using a Series instead of DataFrame"]},{"cell_type":"markdown","metadata":{"id":"FQWEY1DHEcGf"},"source":["If the parsed data only contains one column then we can return a Series by setting the squeeze parameter to True."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXChT0REEcGf"},"outputs":[],"source":["exam_test_1=pd.read_csv('exam_reveiw.csv',\n","            sep='>',\n","            usecols=['last_name'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MggYmrHOEcGf"},"outputs":[],"source":["exam_test_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ut6AW06bEcGf"},"outputs":[],"source":["type(exam_test_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ifqZuYGxEcGg"},"outputs":[],"source":["exam_test_2=pd.read_csv('exam_reveiw.csv',\n","            sep='>',\n","            usecols=['last_name'],\n","            squeeze=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dUH508tEcGg"},"outputs":[],"source":["exam_test_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uk-6JTG5EcGg"},"outputs":[],"source":["type(exam_test_2)"]},{"cell_type":"markdown","metadata":{"id":"_goAuPlZEcGg"},"source":["### Save to CSV file"]},{"cell_type":"markdown","metadata":{"id":"Kao7CijzEcGg"},"source":["Finally we can also save our Dataframe as a CSV file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qsmi_ItxEcGg"},"outputs":[],"source":["exam_df"]},{"cell_type":"markdown","metadata":{"id":"pi5ZmopLEcGh"},"source":["We can simply generate a CSV string from our DataFrame:"]},{"cell_type":"markdown","metadata":{"id":"RE89VZnYEcGh"},"source":["Or specify a file path where we want our generated CSV code to be saved:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtMqWjs9EcGh"},"outputs":[],"source":["exam_df.to_csv('Out.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-yw8IlWEcGh"},"outputs":[],"source":["pd.to_csv('Out.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awhg4eoQEcGh"},"outputs":[],"source":["exam_df.to_csv('Out.csv',\n","              index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MgvDeogXEcGi"},"outputs":[],"source":["pd.to_csv('Out.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}